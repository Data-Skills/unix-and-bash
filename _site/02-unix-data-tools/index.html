<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="last-modified" content="2018-03-13 15:05:10 +0300">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- meta "search-domain" used for google site search function google_search() -->
    <meta name="search-domain" value="">
    <link rel="stylesheet" type="text/css" href="../assets/css/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="../assets/css/bootstrap-theme.css" />
    <link rel="stylesheet" type="text/css" href="../assets/css/lesson.css" />
    <link rel="stylesheet" type="text/css" href="../assets/css/syntax.css" />
    
    <link rel="shortcut icon" type="image/x-icon" href="/favicon-swc.ico" />
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
	<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
	<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
	<![endif]-->
    <title>Intro to UNIX: Unix Data Tools</title>
  </head>
  <body>
    <div class="container">
      
<nav class="navbar navbar-default">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      
      

      
      <a class="navbar-brand" href="../index.html">Home</a>

    </div>
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">

	
        <li><a href="../CONDUCT.html">Code of Conduct</a></li>

        
	
        <li><a href="../setup.html">Setup</a></li>

        
        <li class="dropdown">
          <a href="../" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Episodes <span class="caret"></span></a>
          <ul class="dropdown-menu">
            
            <li><a href="../01-unix-git-intro/index.html">Unix Basics</a></li>
            
            <li><a href="../02-unix-data-tools/index.html">Unix Data Tools</a></li>
            
            <li><a href="../03-bash-scripts/index.html">Shell Scripting, Writing Pipelines, and Parallelizing Tasks</a></li>
            
            <li><a href="../04-git/index.html">Git for Scientists</a></li>
            
	    <li role="separator" class="divider"></li>
            <li><a href="../aio.html">All in one page (Beta)</a></li>
          </ul>
        </li>
	

	
	
        <li class="dropdown">
          <a href="../" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Extras <span class="caret"></span></a>
          <ul class="dropdown-menu">
            <li><a href="../reference.html">Reference</a></li>
            
            <li><a href="../about/index.html">About</a></li>
            
            <li><a href="../discuss/index.html">Discussion</a></li>
            
            <li><a href="../figures/index.html">Figures</a></li>
            
            <li><a href="../guide/index.html">Instructor Notes</a></li>
            
          </ul>
        </li>
	

	
        <li><a href="../LICENSE.html">License</a></li>
	
	<li><a href="/edit/gh-pages/_episodes/02-unix-data-tools.md">Improve this page <span class="glyphicon glyphicon-pencil" aria-hidden="true"></span></a></li>
	
      </ul>
      <form class="navbar-form navbar-right" role="search" id="search" onsubmit="google_search(); return false;">
        <div class="form-group">
          <input type="text" id="google-search" placeholder="Search..." aria-label="Google site search">
        </div>
      </form>
    </div>
  </div>
</nav>


<div class="row">
  <div class="col-xs-1">
    <h3 class="text-left">
      
      <a href="../01-unix-git-intro/index.html"><span class="glyphicon glyphicon-menu-left" aria-hidden="true"></span><span class="sr-only">previous episode</span></a>
      
    </h3>
  </div>
  <div class="col-xs-10">
    
    <h3 class="maintitle"><a href="../">Intro to UNIX</a></h3>
    
  </div>
  <div class="col-xs-1">
    <h3 class="text-right">
      
      <a href="../03-bash-scripts/index.html"><span class="glyphicon glyphicon-menu-right" aria-hidden="true"></span><span class="sr-only">next episode</span></a>
      
    </h3>
  </div>
</div>

<article>
<div class="row">
  <div class="col-md-1">
  </div>
  <div class="col-md-10">
    <h1 class="maintitle">Unix Data Tools</h1>
  </div>
  <div class="col-md-1">
  </div>
</div>


<blockquote class="objectives">
  <h2>Overview</h2>

  <div class="row">
    <div class="col-md-3">
      <strong>Teaching:</strong> 50 min
      <br/>
      <strong>Exercises:</strong> 10 min
    </div>
    <div class="col-md-9">
      <strong>Questions</strong>
      <ul>
	
	<li><p>How do I download and check data?</p>
</li>
	
	<li><p>How to inspect data?</p>
</li>
	
	<li><p>How to view data in Unix?</p>
</li>
	
	<li><p>How to obtain data summary information of my data?</p>
</li>
	
	<li><p>How do I select specific columns from my dataset?</p>
</li>
	
	<li><p>How do I find patterns in my data?</p>
</li>
	
	<li><p>How do I edit data streams?</p>
</li>
	
      </ul>
    </div>
  </div>

  <div class="row">
    <div class="col-md-3">
    </div>
    <div class="col-md-9">
      <strong>Objectives</strong>
      <ul>
	
	<li><p>To be able to download data in Unix.</p>
</li>
	
	<li><p>To be able to inspect and view data in Unix.</p>
</li>
	
	<li><p>To be able to select specific columns in the data files.</p>
</li>
	
	<li><p>To be able to find specific patterns in the data.</p>
</li>
	
	<li><p>To be able to edit data streams.</p>
</li>
	
      </ul>
    </div>
  </div>

</blockquote>

<p><strong>Note:</strong> The lesson is based on Chapters 6 and 7 of the 
<a href="http://shop.oreilly.com/product/0636920030157.do">Bioinformatics Data Skills</a> 
by <a href="https://github.com/vsbuffalo">Vince Buffalo</a></p>

<h1 id="bioinformatic-data">Bioinformatic data</h1>
<h2 id="retrieving-bioinformatic-data">Retrieving bioinformatic data</h2>

<h3 id="downloading-data-with-wget-and-curl">Downloading Data with wget and curl</h3>
<p>Two common command-line programs for downloading data from the Web are 
<a href="https://www.gnu.org/software/wget/">wget</a> and <a href="https://curl.haxx.se/">curl</a>. 
If they are not installed on your system, you’ll have to install them 
with a package manager (e.g., Homebrew or apt-get). While <code class="highlighter-rouge">curl</code> and <code class="highlighter-rouge">wget</code> 
are similar in basic functionality, their relative strengths are different:</p>
<ul>
  <li><code class="highlighter-rouge">wget</code> is useful for quickly downloading a file from the command line</li>
  <li><code class="highlighter-rouge">curl</code> is used in scripts that send data to a system or recieve data through a variate of protocols, including SFTP and SCP.</li>
</ul>

<p>To get a file with data for human chromosome 22 from the GRCh37 (also known as hg19) assembly version:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">wget</span><span class="w"> </span><span class="n">http</span><span class="o">://</span><span class="n">hgdownload.soe.ucsc.edu</span><span class="o">/</span><span class="n">goldenPath</span><span class="o">/</span><span class="n">hg19</span><span class="o">/</span><span class="n">chromosomes</span><span class="o">/</span><span class="n">chr22.fa.gz</span><span class="w">
</span></code></pre></div></div>

<p>Notice that the link to chromosome 22 begins with “http” (short for Hyper‐Text Transfer Protocol). 
<code class="highlighter-rouge">wget</code> can also handle FTP links (which start with “ftp,” short for File Transfer Protocol). 
In general, FTP is preferable to HTTP for large files (and is often recommended by websites like 
the UCSC Genome Browser).</p>

<p>To download chromosome 22 with curl, we’d use:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">curl</span><span class="w"> </span><span class="n">http</span><span class="o">://</span><span class="n">hgdownload.soe.ucsc.edu</span><span class="o">/</span><span class="n">goldenPath</span><span class="o">/</span><span class="n">hg19</span><span class="o">/</span><span class="n">chromosomes</span><span class="o">/</span><span class="n">chr22.fa.gz</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">chr22.fa.gz</span><span class="w">
</span></code></pre></div></div>

<h3 id="data-integrity">Data Integrity</h3>
<p>Data we download into our project directory is the starting point of all future 
analyses and conclusions. So it’s important to explicitly check the transferred 
data’s integrity with check‐sums. Checksums are very compressed summaries of data, 
computed in a way that even if just one bit of the data is changed, the checksum 
will be different. As such data integrity checks are also helpful in keeping track
of data versions. Checksums facilitate reproducibility, as we can link a particular 
analysis and set of results to an exact version of data summarized by the 
data’s checksum value.</p>

<h4 id="sha-and-md5-checksums">SHA and MD5 Checksums</h4>
<p>The two most common checksum algorithms are MD5 and SHA-1. SHA-1 is newer and generally 
preferred. However, MD5 is more common; it’s likely to be what you encounter if a server 
has precomputed checksums on a set of files. To create checksums using SHA-1 we can pass 
arbitrary strings to the program shasum (on some systems, 
it’s sha1sum) through standard in:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">echo</span><span class="w"> </span><span class="s2">"bioinformatics is fun"</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">shasum</span><span class="w">
</span><span class="n">echo</span><span class="w"> </span><span class="s2">"bioinformatic is fun"</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">shasum</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>f9b70d0d1b0a55263f1b012adab6abf572e3030b  -
e7f33eedcfdc9aef8a9b4fec07e58f0cf292aa67  -
</code></pre></div></div>

<p>Checksums are reported in hexadecimal format, where each digit can be one of 16 characters: 
digits 0 through 9, and the letters a, b, c, d, e, and f. The trailing dash indicates this 
is the SHA-1 checksum of input from standard in.</p>

<p>We can also use checksums with file input:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">shasum</span><span class="w"> </span><span class="n">chr22.fa.gz</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>d012edd46f50d674380460d3b4e91f450688e756  chr22.fa.gz
</code></pre></div></div>

<p>Because it can get rather tedious to check each checksum individually <code class="highlighter-rouge">shasum</code> has a convenient 
solution: it can create and validate against a file containing the checksums of files. We can 
create a SHA-1 checksum file for all FASTQ files in the data/ directory as follows:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">shasum</span><span class="w"> </span><span class="n">data</span><span class="o">/*</span><span class="n">fastq</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">fastq_checksums.sha</span><span class="w">
</span></code></pre></div></div>

<p>Then, we can use shasum’s check option (-c) to validate that these files match the original versions:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">shasum</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">fastq_checksums.sha</span><span class="w">
</span></code></pre></div></div>

<p>The program <code class="highlighter-rouge">md5sum</code> (or <code class="highlighter-rouge">md5</code> on OS X) calculates MD5 hashes and is similar in operation to <code class="highlighter-rouge">shasum</code>. 
However, note that on OS X, the md5 command doesn’t have the -c option, so you’ll need to install the 
GNU version for this option.</p>

<blockquote class="callout">
  <h2 id="keeping-records">Keeping records</h2>

  <p>When we download data from the internet, it’s important to include checksum numbers in a README.md file
for reproducibility, e.g.,</p>

  <h3 id="genome-and-annotation-data">Genome and Annotation Data</h3>

  <p>Mouse (<em>Mus musculus</em>) reference genome version GRCm38 (Ensembl
   release 74) was downloaded on Sat Feb 22 21:24:42 PST 2014, using:
       wget ftp://ftp.ensembl.org/pub/release-74/fasta/mus_musculus/dna/Mus_musculus.GRCm38.74.dna.toplevel.fa.gz
   Gene annotation data (also Ensembl release 74) was downloaded from Ensembl on
   Sat Feb 22 23:30:27 PST 2014, using:
       wget ftp://ftp.ensembl.org/pub/release-74/fasta/mus_musculus/dna/Mus_musculus.GRCm38.74.gtf.gz
   ## SHA-1 Sums
    - <code class="highlighter-rouge">Mus_musculus.GRCm38.74.dna.toplevel.fa.gz</code>: 01c868e22a9815c[…]c2154c20ae7899c5f
    - <code class="highlighter-rouge">Mus_musculus.GRCm38.74.gtf.gz</code>: cf5bb5f8bda2803[…]708bff59cb575e379</p>

  <p>Although this isn’t a lot of documentation, this is infinitely better than not documenting how data was 
acquired. As this example demonstrates, it takes very little effort to properly track the data that 
enters your project, and thereby ensure reproducibility. The most important step in documenting your work 
is that you’re consistent and make it a habit.</p>

</blockquote>

<h1 id="unix-data-tools">Unix data tools</h1>
<h2 id="inspecting-and-manipulating-text-data-with-unix-tools">Inspecting and Manipulating Text Data with Unix Tools</h2>

<p><img src="../images/unix2.jpg" align="right" hspace="10" /></p>

<p>In this lesson, we’ll learn how to use core Unix tools to manipulate and explore plain-text 
data formats. The most common tabular plain-text file format used in bioinformatics is 
tab-delimited. Many Unix tools assume tab-delimited file format by default. Such format is also 
simple to parse with scripting languages like Python and Perl, and easy to load into R.</p>

<blockquote class="callout">
  <h2 id="tabular-plain-text-data-formats">Tabular Plain-Text Data Formats</h2>
  <p>The basic tabular data format is incredibly simple: each row (also known as a record) is kept 
on its own line, and each column (also known as a field) is separated by some delimiter. There 
are three flavors you will encounter: tab-delimited, comma-separated, and variable space-delimited. 
Of these three formats, tab-delimited is the most commonly used in bioinformatics. File formats 
such as BED, GTF/GFF, SAM, tabular BLAST output, and VCF are all examples of tab-delimited files. 
Columns of a tab-delimited file are separated by a single tab character (which has the escape code \t). 
A common convention (but not a standard) is to include metadata on the first few lines of a 
tab-delimited file. These metadata lines begin with # to differentiate them from the tabular data 
records. Because tab-delimited files use a tab to delimit columns, tabs in data are not allowed. 
In general, tab-delimited formats and CSV are better choices than space-delimited formats because 
it’s quite common to encounter data containing spaces.<br />
Despite the simplicity of tabular data formats, there’s one major common 
headache: how lines are separated. Linux and OS X use a single linefeed character 
(with the escape code \n) to separate lines, while Windows uses a DOS-style line separator of a carriage 
return and a linefeed character (\r\n). CSV files generally use this DOS-style too, as this is specified 
in the CSV specification RFC-4180 (which in practice is loosely followed). Occasionally, you might encounter 
files separated by only carriage returns.</p>
</blockquote>

<p>In this lesson, we’ll work with very simple genomic feature formats: BED (Browser Extensible Data) 
and GTF (Gene Transfer Format) files. 
These file formats store the positions of features such as genes, exons, and variants in tab-delimited 
format. Don’t worry too much about the specifics of these formats; our goal here is to develop the 
skills to freely manipulate plain-text files or streams using Unix data tools.</p>

<hr />

<h3 id="inspecting-data-with-head-and-tail">Inspecting Data with <code class="highlighter-rouge">head</code> and <code class="highlighter-rouge">tail</code></h3>
<p>Although we can print the content of a file on screen with <code class="highlighter-rouge">cat</code>, a better option is to take a look
at the top of a file with <code class="highlighter-rouge">head</code> and at the bottom of the file with <code class="highlighter-rouge">tail</code>. First, download the file 
Mus_musculus.GRCm38.75_chr1.bed (we downloaded them already when we cloned the bds-files repository):</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">curl</span><span class="w"> </span><span class="o">-</span><span class="n">O</span><span class="w"> </span><span class="n">https</span><span class="o">://</span><span class="n">raw.githubusercontent.com</span><span class="o">/</span><span class="n">Data</span><span class="o">-</span><span class="n">Skills</span><span class="o">/</span><span class="n">bds</span><span class="o">-</span><span class="n">files</span><span class="o">/</span><span class="n">master</span><span class="o">/</span><span class="n">chapter</span><span class="m">-07</span><span class="o">-</span><span class="n">unix</span><span class="o">-</span><span class="n">data</span><span class="o">-</span><span class="n">tools</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.bed</span><span class="w">
</span><span class="n">curl</span><span class="w"> </span><span class="o">-</span><span class="n">O</span><span class="w"> </span><span class="n">https</span><span class="o">://</span><span class="n">raw.githubusercontent.com</span><span class="o">/</span><span class="n">Data</span><span class="o">-</span><span class="n">Skills</span><span class="o">/</span><span class="n">bds</span><span class="o">-</span><span class="n">files</span><span class="o">/</span><span class="n">master</span><span class="o">/</span><span class="n">chapter</span><span class="m">-07</span><span class="o">-</span><span class="n">unix</span><span class="o">-</span><span class="n">data</span><span class="o">-</span><span class="n">tools</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w">
</span></code></pre></div></div>

<p>Now look at it with <code class="highlighter-rouge">head</code>:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="n">Mus_musculus.GRCm38.75_chr1.bed</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1	3054233	3054733
1	3054233	3054733
1	3054233	3054733
</code></pre></div></div>

<p>The -n argument controls how many lines to display (the default is 10).
<code class="highlighter-rouge">head</code> has a related command designed to look at the end, or <code class="highlighter-rouge">tail</code> of a file:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tail</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="n">Mus_musculus.GRCm38.75_chr1.bed</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1	195240910	195241007
1	195240910	195241007
1	195240910	195241007
</code></pre></div></div>

<p>One common use of <code class="highlighter-rouge">tail</code> is to remove the header of a file. If -n is given a number x 
preceded with a + sign (e.g., +x), tail will start from the xth line. So to chop off a 
header, we start from the second line with -n +2. Here, we’ll use the command seq to 
generate a file of 3 numbers, and chop of the first line:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">seq</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">nums.txt</span><span class="w">
</span><span class="n">cat</span><span class="w"> </span><span class="n">nums.txt</span><span class="w">
</span><span class="n">echo</span><span class="w"> </span><span class="s2">"---"</span><span class="w">
</span><span class="n">tail</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">+2</span><span class="w"> </span><span class="n">nums.txt</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1
2
3
---
2
3
</code></pre></div></div>

<p>Sometimes it’s useful to see both the beginning and end of a file. Foor example, if we have a 
sorted BED file and we want to see the positions of the first feature and last feature. 
We can do this using Unix subshell, the topic we’ll cover later:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">2</span><span class="p">;</span><span class="w"> </span><span class="n">tail</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Mus_musculus.GRCm38.75_chr1.bed</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1	3054233	3054733
1	3054233	3054733
1	195240910	195241007
1	195240910	195241007
</code></pre></div></div>

<p>We can create even a short‐cut for this command
in your shell configuration file, which is either ~/.bashrc or ~/.profile:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># inspect the first and last 3 lines of a file</span><span class="w">
</span><span class="n">i</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="p">(</span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">2</span><span class="p">;</span><span class="w"> </span><span class="n">tail</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="s2">"$1"</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">column</span><span class="w"> </span><span class="o">-</span><span class="n">t</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p><code class="highlighter-rouge">head</code> is also useful for taking a peek at data resulting from a Unix pipeline:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="s1">'gene_id "ENSMUSG00000025907"'</span><span class="w"> </span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">1</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1	protein_coding	gene	6206197	6276648	.	+	.	gene_id "ENSMUSG00000025907"; gene_name "Rb1cc1"; gene_source "ensembl_havana"; gene_biotype "protein_coding";
</code></pre></div></div>

<p>After printing the first few rows of your data the head process exits. When it exits, 
the shell sends a signal to other programs in the pipe called SIGPIPE, much like the 
signal that’s sent when you press Control-c (that signal is SIGINT) that terminates them
as well. When building complex pipelines that process large amounts of data, 
this is extremely important feature.</p>

<hr />

<h3 id="viewing-data-with-less">Viewing data with <code class="highlighter-rouge">less</code></h3>
<p><code class="highlighter-rouge">less</code> is a terminal pager, a program that allows us to view large amounts of 
text in our terminals by scrolling through long files and standard output a 
screen at a time. Once we start less, it will stay open until we quit it by 
pressing <code class="highlighter-rouge">q</code>. Some other commands in <code class="highlighter-rouge">less</code> are listed in the table below:</p>

<p><img src="../images/table7.1.png" alt="" /></p>

<blockquote class="challenge">
  <h2 id="challenge-1">Challenge 1</h2>

  <p>Let’s look at a file called contaminated.fastq in the book’s GitHub repository.
Use less to get a quick sense of whether 
there are 3’ adapter contaminants in the contaminated.fastq file. We’ll look for 
AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC (a known adapter from the Illumina Tru‐ Seq® kit1). 
Instead of trying to find the complete sequence, let’s search for the first 11 bases, 
AGATCGGAAGA.</p>

  <ul>
    <li>What less commad will you use to search for this sequence?</li>
    <li>Are the sequences contaminated?</li>
  </ul>
</blockquote>

<p><code class="highlighter-rouge">less</code> is also extremely useful in debugging our command-line pipelines. You can 
pipe the output of the command you want to debug to less and comment out everything 
after. When you run the pipe, less will capture the output of the last command and 
pause so you can inspect it.</p>

<p><code class="highlighter-rouge">less</code> is also crucial when iteratively building up a pipeline. Suppose we have an 
imaginary pipeline that involves three programs, step1, step2, and step3. Our 
finished pipeline will look like<br />
<code class="highlighter-rouge">step1 input.txt | step2 | step3 &gt; output.txt</code>. But we may want to build it up in 
pieces, checking the output of each step. The natural way to do this is with less:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">step1</span><span class="w"> </span><span class="n">input.txt</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">less</span><span class="w"> </span><span class="c1"># inspect output in less </span><span class="w">
</span><span class="n">step1</span><span class="w"> </span><span class="n">input.txt</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">step2</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">less</span><span class="w">
</span><span class="n">step1</span><span class="w"> </span><span class="n">input.txt</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">step2</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">step3</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">less</span><span class="w">
</span></code></pre></div></div>

<p>A useful behavior of pipes is that the execution of a program with output piped to 
<code class="highlighter-rouge">less</code> will be paused when <code class="highlighter-rouge">less</code> has a full screen of data. The result is that we 
can throw less after a complex pipe processing large data and not worry about wasting 
computing power: the pipe will block and we can spend as much time as needed to inspect 
the output.</p>

<hr />

<h3 id="obtaining-plain-text-data-summary-information-with-wc-ls-and-awk">Obtaining plain-Text Data Summary Information with <code class="highlighter-rouge">wc</code>, <code class="highlighter-rouge">ls</code>, and <code class="highlighter-rouge">awk</code></h3>
<p>In addition to peeking at a file with <code class="highlighter-rouge">head</code>, <code class="highlighter-rouge">tail</code>, or <code class="highlighter-rouge">less</code>, we may want other 
bits of summary information about a plain-text data file like the number of rows or 
columns. With plain-text data formats like tab-delimited and CSV files, the number 
of rows is usually the number of lines. We can retrieve this with the program <code class="highlighter-rouge">wc</code> (for word count):</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">wc</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.bed</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   81226  243678 1698545 ../data/Mus_musculus.GRCm38.75_chr1.bed
</code></pre></div></div>

<p>By default, wc outputs the number of words, lines, and characters of the supplied file. Often, 
we only care about the number of lines. We can use option -l to just return the number of lines:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">wc</span><span class="w"> </span><span class="o">-</span><span class="n">l</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.bed</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   81226 ../data/Mus_musculus.GRCm38.75_chr1.bed
</code></pre></div></div>

<p>Another bit of information we usually want about a file is its size. The easiest way to do this is 
with our old Unix friend, <code class="highlighter-rouge">ls</code>, with the -lh option (l for long, h for human-readable:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ls</span><span class="w"> </span><span class="o">-</span><span class="n">lh</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.bed</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-rw-r--r--  1 dlavrov  staff   1.6M Mar  6 06:35 ../data/Mus_musculus.GRCm38.75_chr1.bed
</code></pre></div></div>

<blockquote class="challenge">
  <h2 id="challenge-2">Challenge 2</h2>

  <p>Let’s look at two files we downloaded earlier, Mus_musculus.GRCm38.75_chr1.gtf and 
Mus_musculus.GRCm38.75_chr1.bed.</p>
  <ul>
    <li>What are the sizes of these files?</li>
    <li>How many lines they contain?</li>
  </ul>

</blockquote>

<p>Note that “M” in <code class="highlighter-rouge">ls -lh</code> output indicates megabytes; “G” – gigabytes.</p>

<hr />

<h3 id="finding-the-number-of-columns-with-awk">Finding the number of columns with <code class="highlighter-rouge">awk</code></h3>

<p>There’s one other bit of information we often want about a file: how many columns it contains. 
We could always manually count the number of columns of the first row with head -n 1, but a far 
easier way is to use <code class="highlighter-rouge">awk</code>. <code class="highlighter-rouge">Awk</code> is an easy, small programming language great at working with 
text data like TSV and CSV files. We’ll see more of `awk later, but let’s use an awk one-liner 
to return how many fields a file contains:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">awk</span><span class="w"> </span><span class="o">-</span><span class="nb">F</span><span class="w"> </span><span class="s2">"\t"</span><span class="w"> </span><span class="s1">'{print NF; exit}'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.bed</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3
</code></pre></div></div>

<p><code class="highlighter-rouge">awk</code> was designed for tabular plain-text data processing, and
has a built-in variable NF set to the number of fields of the current dataset. 
This awk oneliner simply prints the number of fields of the first row 
of the Mus_musculus.GRCm38.75_chr1.bed file, and then exits. By default, <code class="highlighter-rouge">awk</code> 
treats white‐space (tabs and spaces) as the field separator, but we changed
this to just tabs by setting the -F argument of <code class="highlighter-rouge">awk</code>.</p>

<p>Finding how many columns there are in Mus_musculus.GRCm38.75_chr1.gtf is a bit 
trickier because this file has a series of comments in the beginning (marked with #) 
that contain helpful metadata like the genome build, version, date, and accession 
number. One way to fix this is with a tail trick we saw earlier:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tail</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">+6</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">1</span><span class="p">;</span><span class="w">
</span><span class="n">echo</span><span class="w"> </span><span class="s2">"---"</span><span class="w">
</span><span class="n">tail</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">+6</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">awk</span><span class="w"> </span><span class="o">-</span><span class="nb">F</span><span class="w"> </span><span class="s2">"\t"</span><span class="w"> </span><span class="s1">'{print NF; exit}'</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1	pseudogene	gene	3054233	3054733	.	+	.	gene_id "ENSMUSG00000090025"; gene_name "Gm16088"; gene_source "havana"; gene_biotype "pseudogene";
---
9
</code></pre></div></div>

<p>A better solution would be to simply exclude all lines that match a comment line pattern. 
Using the program grep (which we’ll talk more about it later), we can easily exclude lines 
that begin with “#”:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="o">-</span><span class="n">v</span><span class="w"> </span><span class="s2">"^#"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">awk</span><span class="w"> </span><span class="o">-</span><span class="nb">F</span><span class="w"> </span><span class="s2">"\t"</span><span class="w"> </span><span class="s1">'{print NF; exit}'</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>9
</code></pre></div></div>

<hr />

<h3 id="working-with-column-data-with-cut-and-column">Working with Column Data with <code class="highlighter-rouge">cut</code> and <code class="highlighter-rouge">column</code></h3>

<p>There is another useful program for  working with plain-text tabular data formats: <code class="highlighter-rouge">cut</code>. 
<code class="highlighter-rouge">Cut</code> cuts out specified columns (also known as fields) from a text file. By default, 
cut treats tabs as the delimiters, so to extract the second column we use:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cut</span><span class="w"> </span><span class="o">-</span><span class="n">f</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.bed</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">3</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3054233
3054233
3054233
</code></pre></div></div>

<p>The -f argument is how we specify which columns to keep. The argument -f also allows 
us to specify ranges of columns (e.g., -f 3-8) and sets of columns (e.g., -f 3,5,8). 
Note that it’s not possible to reorder columns using using <code class="highlighter-rouge">cut</code> (e.g., -f 6,5,4,3 will 
not work, unfortunately). But you can use <code class="highlighter-rouge">awk -v OFS="\t" '{ print $6,$5,$4,$3 }'</code> 
(see extra topics for more info).</p>

<blockquote class="challenge">
  <h2 id="challenge-3">Challenge 3</h2>

  <p>Use cut to convert our GTF for Mus_musculus.GRCm38.75_chr1.gtf to a three-column 
tab-delimited file of genomic ranges (e.g., chromosome, start, and end position).
Note that although our three-column file of genomic positions looks like a 
BED-formatted file, it’s not due to subtle differences in genomic range formats. 
We’ll learn more about this later.</p>

</blockquote>

<hr />

<h3 id="formatting-tabular-data-with-column">Formatting Tabular Data with <code class="highlighter-rouge">column</code></h3>
<p>As you may have noticed when working with tab-delimited files, it’s not always easy to see which 
elements belong to a particular column. For example:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="o">-</span><span class="n">v</span><span class="w"> </span><span class="s2">"^#"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">cut</span><span class="w"> </span><span class="o">-</span><span class="n">f</span><span class="m">1-8</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">3</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1	pseudogene	gene	3054233	3054733	.	+	.
1	unprocessed_pseudogene	transcript	3054233	3054733	.	+	.
1	unprocessed_pseudogene	exon	3054233	3054733	.	+	.
</code></pre></div></div>

<p>While tabs are a terrific delimiter in plain-text data files, our variable width data leads our 
columns to not stack up well. There’s a fix for this in Unix: program <code class="highlighter-rouge">column -t</code> (the -t option 
tells column to treat data as a table). <code class="highlighter-rouge">column -t</code> produces neat columns that are much easier to 
read:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="o">-</span><span class="n">v</span><span class="w"> </span><span class="s2">"^#"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">cut</span><span class="w"> </span><span class="o">-</span><span class="n">f</span><span class="m">1-8</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">column</span><span class="w"> </span><span class="o">-</span><span class="n">t</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">3</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1  pseudogene                          gene         3054233    3054733    .  +  .
1  unprocessed_pseudogene              transcript   3054233    3054733    .  +  .
1  unprocessed_pseudogene              exon         3054233    3054733    .  +  .
</code></pre></div></div>

<p>Note that you should only use <code class="highlighter-rouge">columnt -t</code> to visualize data in the terminal, not to reformat data 
to write to a file. Tab-delimited data is preferable to data delimited by a variable number of spaces, 
since it’s easier for programs to parse.</p>

<p>Like cut, column’s default delimiter is the tab character (\t). We can specify a different 
delimiter with the -s option.</p>

<p><code class="highlighter-rouge">column</code> illustrates an important point about how we should treat data: 
there’s no reason to make data formats attractive at the expense of readable 
by programs. This relates to the general recommendation: <strong>“write code for 
humans, write data for computers”</strong>. In general, it’s easier to make computer-
readable data attractive to humans than it is to make data in a human-friendly 
format readable to a computer.</p>

<hr />

<h3 id="finding-patterns-with-grep">Finding patterns with <code class="highlighter-rouge">grep</code></h3>

<p><code class="highlighter-rouge">grep</code> finds a pattern (fixed string or regular expression) in a file and is faster than 
any other searches you can do in other programs/languages. <code class="highlighter-rouge">grep</code> requires two arguments: 
the pattern (the string or basic regular expression you want to search for), and the file 
(or files) to search for it in. As a very simple example, let’s use grep to find a gene, 
“Olfr418-ps1,” in the file Mus_musculus.GRCm38.75_chr1_genes.txt (which contains all Ensembl 
gene identifiers and gene names for all protein-coding genes on chromosome 1):</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="s2">"Olfr418-ps1"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1_genes.txt</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ENSMUSG00000049605	Olfr418-ps1
</code></pre></div></div>

<p>Note that although the quotes around the pattern aren’t required, it’s safest to use them 
so our shells won’t try to interpret any symbols. One useful option when using grep is 
–color=auto. This option enables terminal colors, 
so the matching part of the pattern is colored in your terminal.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="o">--</span><span class="n">color</span><span class="o">=</span><span class="n">auto</span><span class="w"> </span><span class="s2">"Olfr"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1_genes.txt</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">5</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ENSMUSG00000067064	Olfr1416
ENSMUSG00000057464	Olfr1415
ENSMUSG00000042849	Olfr1414
ENSMUSG00000058904	Olfr1413
ENSMUSG00000046300	Olfr1412
</code></pre></div></div>

<blockquote class="callout">
  <h2 id="gnu-bsd-and-the-flavors-of-grep">GNU, BSD, and the Flavors of Grep</h2>
  <p>Up until now, we’ve glossed over a very important detail: there are different implementations 
of Unix tools. Tools like grep, cut, and sort come from one of two flavors: BSD utils and GNU coreutils. 
Both of these implementations contain all standard Unix tools we use in this chapter, but their features 
may slightly differ from each other. BSD’s tools are found on Max OS X and other <em>Berkeley Software 
Distribution</em>-derived operating systems like FreeBSD. GNU’s coreutils are the standard set of tools found 
on Linux systems. It’s important to know which implementation you’re using (this is easy to tell by reading 
the man page). If you’re using Mac OS X and would like to use GNU coreutils, you can install these through 
Homebrew with brew install coreutils. Each program will install with the prefix “g” (e.g., cut would be 
aliased to gcut), so as to not interfere with the system’s default tools.
Unlike BSD’s utils, GNU’s coreutils are still actively developed. GNU’s coreutils also have many more 
features and extensions than BSD’s utils, some of which we use in this chapter. In general, you should use 
GNU’s coreutils over BSD utils, as the documen‐tation is more thorough and the GNU extensions are helpful.</p>

</blockquote>

<p>Note, that when we specify a pattern in grep, we’ll also get all the words that partially match
this pattern (e.g., specifying “mito” will also get us “Not-mito”). To get around this, use -w 
to match entire words (strings of characters surrounded by whitespace).</p>

<blockquote class="challenge">
  <h2 id="challenge-4">Challenge 4</h2>

  <p>Find all the lines in Mus_musculus.GRCm38.75_chr1_genes.txt correspoding to gene names that begin 
with Olfr.<br />
What unix command can you use to count their number?</p>

</blockquote>

<p>grep’s default output often doesn’t give us enough context of a match when we need to inspect 
results by eye. There are three useful options to get around this: context before (-B), \context after (-A), and context before and after (-C). Each of these arguments takes how many lines of 
context to provide (e.g., -A2)</p>

<p>grep also supports a flavor of regular expression called POSIX Basic Regular 
Expressions (BRE). If you’re familiar with the regular expressions in Perl or 
Python, you’ll notice that grep’s regular expressions aren’t quite as powerful 
as the ones in these lan‐guages. Still, for many simple applications they work 
quite well. For example, if we wanted to find the Ensembl gene identifiers for 
both “Olfr1413” and “Olfr1411,” we could use:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="s2">"Olfr141[13]"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1_genes.txt</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ENSMUSG00000058904	Olfr1413
ENSMUSG00000062497	Olfr1411
</code></pre></div></div>

<p>However, this approach is less useful if we have more divergent patterns to search for. 
For example, constructing a BRE pattern to match both “Olfr218” and “Olfr1416” would be 
complex and error prone. For tasks like these, it’s far easier to use grep’s support for 
POSIX Extended Regular Expressions (ERE). <code class="highlighter-rouge">grep</code> allows us to turn on ERE with the -E 
option (which on many systems is aliased to egrep). EREs allow us to use 
alternation to match either “Olfr218” or “Olfr1416.” The syntax uses a pipe symbol (|):</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="o">-</span><span class="n">E</span><span class="w"> </span><span class="s2">"(Olfr1413|Olfr1411)"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1_genes.txt</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ENSMUSG00000058904	Olfr1413
ENSMUSG00000062497	Olfr1411
</code></pre></div></div>

<p>We don’t have time to talk about regular expressions here. The important part is that you 
recognize there’s a difference and know the terms necessary to find further help when you need it.</p>

<p>We used wc -l above to count the number of matches in <code class="highlighter-rouge">grep</code>. However, <code class="highlighter-rouge">grep</code> has an option to do it
itself: -c.  Returning to our previous example counting the genes start with “Olfr”:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="s2">"\tOlfr"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1_genes.txt</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>27
</code></pre></div></div>

<p>Counting matching lines is extremely useful—especially with plain-text data 
where lines represent rows in the data. For example, suppose we wanted to know 
how many small nuclear RNAs are in our Mus_musculus.GRCm38.75_chr1.gtf 
file. snRNAs are annotated as gene_biotype “snRNA” in the last column of this GTF file. 
A simple way to count these features would be:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="s1">'gene_biotype "snRNA"'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>315
</code></pre></div></div>

<p>Note here how we’ve used single quotes to specify our pattern, as our pattern includes 
the double-quote characters (“).</p>

<p>By default, <code class="highlighter-rouge">grep</code> is outputting the entire matching line. Sometimes, however, it’s useful 
to use <code class="highlighter-rouge">grep</code> to extract only the matching part of the pattern. We can do this with -o:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="o">-</span><span class="n">o</span><span class="w"> </span><span class="s2">"Olfr.*"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1_genes.txt</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">5</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Olfr1416
Olfr1415
Olfr1414
Olfr1413
Olfr1412
</code></pre></div></div>

<p>Or, suppose we wanted to extract all values of the “gene_id” field from the last column of our 
Mus_musculus.GRCm38.75_chr1.gtf file. This is easy with -o:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="o">-</span><span class="n">E</span><span class="w"> </span><span class="o">-</span><span class="n">o</span><span class="w"> </span><span class="s1">'gene_id "\w+"'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">5</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gene_id "ENSMUSG00000090025"
gene_id "ENSMUSG00000090025"
gene_id "ENSMUSG00000090025"
gene_id "ENSMUSG00000064842"
gene_id "ENSMUSG00000064842"
</code></pre></div></div>

<p>Here, we’re using extended regular expressions to capture all gene names in the field. However, 
there’s a great deal of redundancy in our results because our GTF file has multiple features 
(transcripts, exons, start codons, etc.) that all have the same gene name. What if you want 
just a list of unique, sorted gene names? We can do it easily in unix:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="o">-</span><span class="n">E</span><span class="w"> </span><span class="o">-</span><span class="n">o</span><span class="w"> </span><span class="s1">'gene_id "\w+"'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">cut</span><span class="w"> </span><span class="o">-</span><span class="n">f</span><span class="m">2</span><span class="w"> </span><span class="o">-</span><span class="n">d</span><span class="s2">" "</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">sed</span><span class="w"> </span><span class="s1">'s/"//g'</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">sort</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">uniq</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">10</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ENSMUSG00000000544
ENSMUSG00000000817
ENSMUSG00000001138
ENSMUSG00000001143
ENSMUSG00000001305
ENSMUSG00000001674
ENSMUSG00000002459
ENSMUSG00000002881
ENSMUSG00000003051
ENSMUSG00000003134
</code></pre></div></div>

<p>As you can see, we are about half-way through the tools we need to learn!</p>

<hr />

<h3 id="sorting-plain-text-data-with-sort">Sorting Plain-Text Data with <code class="highlighter-rouge">sort</code></h3>

<p>Often we need to work with sorted plain-text data in bioinformatics. The two most common reasons to 
sort data are as follows:</p>
<ul>
  <li>Certain operations are much more efficient when performed on sorted data.</li>
  <li>Sorting data is a prerequisite to finding all unique lines, using the Unix <code class="highlighter-rouge">sort | uniq</code> idiom.</li>
</ul>

<p><code class="highlighter-rouge">sort</code>, like <code class="highlighter-rouge">cut</code>, is designed to work with plain-text data with columns. Running
<code class="highlighter-rouge">sort</code> without any arguments simply sorts a file alphanumerically by line:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cat</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example.bed</span><span class="w">
</span><span class="n">echo</span><span class="w"> </span><span class="s2">"======="</span><span class="w">
</span><span class="n">sort</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example.bed</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>chr1	26	39
chr1	32	47
chr3	11	28
chr1	40	49
chr3	16	27
chr1	9	28
chr2	35	54
chr1	10	19
=======
chr1	10	19
chr1	26	39
chr1	32	47
chr1	40	49
chr1	9	28
chr2	35	54
chr3	11	28
chr3	16	27
</code></pre></div></div>

<p>Because chromosome is the first column, sorting by line effectively groups 
chromosomes together, as these are “ties” in the sorted order. Grouped data 
is quite useful, as we’ll see.</p>

<h4 id="using-different-delimiters-with--t">Using Different Delimiters with -t</h4>

<p>By default, sort treats blank characters (like tab or spaces) as field delimiters. 
If your file uses another delimiter (such as a comma for CSV files), you can specify 
the field separator with -t (e.g., -t”,”).</p>

<h4 id="specifying-columns-to-sort-with--k">Specifying columns to sort with -k</h4>

<p>Using sort’s defaults of sorting alphanumerically by line doesn’t handle 
tabular data properly. There are two additional features we need:</p>

<ul>
  <li>The ability to sort by particular columns</li>
  <li>The ability to tell sort that certain columns are numeric values (and not alphanumeric text)</li>
</ul>

<p><code class="highlighter-rouge">sort</code> has a simple syntax to do this:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sort</span><span class="w"> </span><span class="o">-</span><span class="n">k</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="n">k</span><span class="m">2</span><span class="p">,</span><span class="m">2</span><span class="n">n</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example.bed</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>chr1	9	28
chr1	10	19
chr1	26	39
chr1	32	47
chr1	40	49
chr2	35	54
chr3	11	28
chr3	16	27
</code></pre></div></div>

<p>Here, -k specifies the sorting keys and their order. Each -k argument takes a
range of columns as start, end, so to sort by a single column we use start,start. Sorting by 
the first column alone leads to many ties in rows with the same chromosomes (e.g., “chr1” 
and “chr3”). Adding a second -k argument with a different column tells sort how to break 
these ties. In our example, -k2,2n tells sort to sort by the second column (start position), 
treating this column as numerical data (because there’s an n in -k2,2n). If you need all 
columns to be sorted numerically, you can use the argument -n rather
than specifying which particular columns are numeric.</p>

<h4 id="additional-options-in-sort--s--c--r--v">Additional options in sort: -s, -c, -r, -V</h4>

<ul>
  <li>
    <p>When we try to sort two lines are exactly identical according to all 
sorting keys we’ve specified, <code class="highlighter-rouge">sort</code> will sort them according to the entire line. 
If we don’t want sort to change the order of lines that are equal according to our 
sort keys, we can use the -s option, which turns off this last-resort sorting.</p>
  </li>
  <li>
    <p>If you have a file that you suspect is already 
sorted, it’s much cheaper to validate that it’s indeed sorted rather than resort it. 
We can check if a file is sorted according to our -k arguments using -c:</p>
  </li>
  <li>
    <p>If we want to sort in reverse order, we use the -r option.  But notice two possibilities:</p>
  </li>
</ul>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sort</span><span class="w"> </span><span class="o">-</span><span class="n">k</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="n">k</span><span class="m">2</span><span class="p">,</span><span class="m">2</span><span class="n">n</span><span class="w"> </span><span class="o">-</span><span class="n">r</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example.bed</span><span class="w">
</span><span class="n">echo</span><span class="w"> </span><span class="s2">"==========="</span><span class="w">
</span><span class="n">sort</span><span class="w"> </span><span class="o">-</span><span class="n">k</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="n">k</span><span class="m">2</span><span class="p">,</span><span class="m">2</span><span class="n">nr</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example.bed</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>chr3	11	28
chr3	16	27
chr2	35	54
chr1	9	28
chr1	10	19
chr1	26	39
chr1	32	47
chr1	40	49
===========
chr1	40	49
chr1	32	47
chr1	26	39
chr1	10	19
chr1	9	28
chr2	35	54
chr3	16	27
chr3	11	28
</code></pre></div></div>

<p>Finally, GNU sort has an option -V, which is a clever alphanumeric 
sorting routine that understands numbers inside strings. Consider the difference:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gsort</span><span class="w"> </span><span class="o">-</span><span class="n">k</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="n">k</span><span class="m">2</span><span class="p">,</span><span class="m">2</span><span class="n">n</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example2.bed</span><span class="w">
</span><span class="n">echo</span><span class="w"> </span><span class="s2">"==========="</span><span class="w">
</span><span class="n">gsort</span><span class="w"> </span><span class="o">-</span><span class="n">k</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="n">V</span><span class="w"> </span><span class="o">-</span><span class="n">k</span><span class="m">2</span><span class="p">,</span><span class="m">2</span><span class="n">n</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example2.bed</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>chr1	34	49
chr10	30	42
chr10	31	47
chr11	6	16
chr2	15	19
chr2	17	22
chr2	27	46
chr22	32	46
===========
chr1	34	49
chr2	15	19
chr2	17	22
chr2	27	46
chr10	30	42
chr10	31	47
chr11	6	16
chr22	32	46
</code></pre></div></div>

<hr />

<h3 id="finding-unique-values-with-uniq">Finding Unique Values with <code class="highlighter-rouge">uniq</code></h3>

<p><code class="highlighter-rouge">Uniq</code> takes lines from a file or standard input stream, and outputs all 
lines with consecutive duplicates removed. While this is a relatively simple 
functionality, you will use <code class="highlighter-rouge">uniq</code> very frequently in command-line data processing. 
Let’s first see an example of its behavior:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cat</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">letters.txt</span><span class="w">
</span><span class="n">echo</span><span class="w"> </span><span class="s2">"=========="</span><span class="w">
</span><span class="n">uniq</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">letters.txt</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A
A
B
C
B
C
C
C
==========
A
B
C
B
C
</code></pre></div></div>

<p>Because <code class="highlighter-rouge">uniq</code> only removes consecutive duplicate lines (keeping one), if we want to 
find all unique lines in a file, we would first sort all lines using <code class="highlighter-rouge">sort</code> 
and then run <code class="highlighter-rouge">uniq</code>:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sort</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">letters.txt</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">uniq</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A
B
C
</code></pre></div></div>

<p><code class="highlighter-rouge">uniq</code> also has a tremendously useful option that’s used 
very often in command-line data processing: -c. This option shows the counts of occurrences 
next to the unique lines. For example:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">uniq</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">letters.txt</span><span class="w">
</span><span class="n">echo</span><span class="w"> </span><span class="s2">"=========="</span><span class="w">
</span><span class="n">sort</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">letters.txt</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">uniq</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   2 A
   1 B
   1 C
   1 B
   3 C
==========
   2 A
   2 B
   4 C
</code></pre></div></div>

<p>Both <code class="highlighter-rouge">sort | uniq</code> and <code class="highlighter-rouge">sort | uniq -c</code> are frequently used shell idioms in bioinformatics 
and worth memorizing. Combined with other Unix tools like <code class="highlighter-rouge">grep</code> and <code class="highlighter-rouge">cut</code>, <code class="highlighter-rouge">sort</code> and <code class="highlighter-rouge">uniq</code> 
can be used to summarize columns of tabular data:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="o">-</span><span class="n">v</span><span class="w"> </span><span class="s2">"^#"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">cut</span><span class="w"> </span><span class="o">-</span><span class="n">f</span><span class="m">3</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">sort</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">uniq</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>25901 CDS
7588 UTR
36128 exon
2027 gene
2290 start_codon
2299 stop_codon
4993 transcript
</code></pre></div></div>

<p>Because <code class="highlighter-rouge">sort</code> and <code class="highlighter-rouge">uniq</code> are line-based, we can create lines from multiple columns to count 
combinations, like how many of each feature (column 3 in this example GTF) are on each 
strand (column 7):</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="o">-</span><span class="n">v</span><span class="w"> </span><span class="s2">"^#"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">cut</span><span class="w"> </span><span class="o">-</span><span class="n">f</span><span class="m">3</span><span class="p">,</span><span class="m">7</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">sort</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">uniq</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12891 CDS	+
13010 CDS	-
3754 UTR	+
3834 UTR	-
18134 exon	+
17994 exon	-
1034 gene	+
 993 gene	-
1135 start_codon	+
1155 start_codon	-
1144 stop_codon	+
1155 stop_codon	-
2482 transcript	+
2511 transcript	-
</code></pre></div></div>

<p>Or, if you want to see the number of features belonging to a particular gene identifier:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="s2">"ENSMUSG00000033793"</span><span class="w"> </span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">cut</span><span class="w"> </span><span class="o">-</span><span class="n">f</span><span class="m">3</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">sort</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">uniq</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  13 CDS
   3 UTR
  14 exon
   1 gene
   1 start_codon
   1 stop_codon
   1 transcript
</code></pre></div></div>

<p>These count tables are incredibly useful for summarizing columns of categorical data. 
Without having to load data into a program like R or Excel, we can quickly calculate 
summary statistics about our plain-text data files.</p>

<p><code class="highlighter-rouge">uniq</code> can also be used to check for duplicates with the -d option, which tells the program
to output duplicated lines only. For example, the mm_gene_names.txt file (which contains a 
list of gene names) does not have duplicates:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">uniq</span><span class="w"> </span><span class="o">-</span><span class="n">d</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">mm_gene_names.txt</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">wc</span><span class="w"> </span><span class="o">-</span><span class="n">l</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>       0
</code></pre></div></div>

<p>A file with duplicates, like the test.bed file, has multiple lines returned:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">uniq</span><span class="w"> </span><span class="o">-</span><span class="n">d</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">test.bed</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">wc</span><span class="w"> </span><span class="o">-</span><span class="n">l</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>       0
</code></pre></div></div>

<hr />

<h3 id="joining-two-files-with-join">Joining two files with <code class="highlighter-rouge">join</code></h3>
<p>The Unix tool join is used to join different files together by a common column. For example,
we may want to add chromosome lengths recorded in example_lengths.txt to example.bed BED file, 
we saw earlier. The files look like this:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cat</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example.bed</span><span class="w">
</span><span class="n">echo</span><span class="w"> </span><span class="s2">"=========="</span><span class="w">
</span><span class="n">cat</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example_lengths.txt</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>chr1	26	39
chr1	32	47
chr3	11	28
chr1	40	49
chr3	16	27
chr1	9	28
chr2	35	54
chr1	10	19
==========
chr1	58352
chr2	39521
chr3	24859
</code></pre></div></div>

<p>To do this, we need to join both of these tabular files by their common column, 
the one containing the chromosome names. But first, we first need to sort both 
files by the column to be joined on (join would not work otherwise):</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sort</span><span class="w"> </span><span class="o">-</span><span class="n">k</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example.bed</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example_sorted.bed</span><span class="w">
</span><span class="n">sort</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="o">-</span><span class="n">k</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example_lengths.txt</span><span class="w"> </span><span class="c1"># verifies is already sorted</span><span class="w">
</span></code></pre></div></div>

<p>The basic syntax is <code class="highlighter-rouge">join -1 &lt;file_1_field&gt; -2 &lt;file_2_field&gt; &lt;file_1&gt; &lt;file_2&gt;</code>. So, with 
example.bed and example_lengths.txt this would be:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">join</span><span class="w"> </span><span class="m">-1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">-2</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example_sorted.bed</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example_lengths.txt</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example_with_lengths.txt</span><span class="w">
</span><span class="n">cat</span><span class="w"> </span><span class="n">example_with_lengths.txt</span><span class="w">
</span></code></pre></div></div>

<p>There are many types of joins. For now, it’s important that we make sure join is working 
as we expect. Our expectation is that this join should not lead to fewer rows than in our 
example.bed file. We can verify this with wc -l:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">wc</span><span class="w"> </span><span class="o">-</span><span class="n">l</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example_sorted.bed</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example_with_lengths.txt</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>       8 ../data/example_sorted.bed
       8 ../data/example_with_lengths.txt
      16 total
</code></pre></div></div>

<p>However, look what happens if our second file, example_lengths.txt doesn’t have the 
lengths for chr3:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="m">2</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example_lengths.txt</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example_lengths_alt.txt</span><span class="w"> </span><span class="c1">#truncate file</span><span class="w">
</span><span class="n">join</span><span class="w"> </span><span class="m">-1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">-2</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example_sorted.bed</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example_lengths_alt.txt</span><span class="w">
</span><span class="n">join</span><span class="w"> </span><span class="m">-1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">-2</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example_sorted.bed</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example_lengths_alt.txt</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">wc</span><span class="w"> </span><span class="o">-</span><span class="n">l</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>chr1 10 19 58352
chr1 26 39 58352
chr1 32 47 58352
chr1 40 49 58352
chr1 9 28 58352
chr2 35 54 39521
       6
</code></pre></div></div>

<p>Because chr3 is absent from example_lengths_alt.txt, our join omits rows from 
example_sorted.bed that do not have an entry in the first column of 
example_lengths_alt.txt. If we don’t want this behavior, we can use option -a 
to include unpairable lines—ones that do not have an entry in either file:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gjoin</span><span class="w"> </span><span class="m">-1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">-2</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="n">a</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example_sorted.bed</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example_lengths_alt.txt</span><span class="w"> </span><span class="c1"># GNU join only</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>chr1 10 19 58352
chr1 26 39 58352
chr1 32 47 58352
chr1 40 49 58352
chr1 9 28 58352
chr2 35 54 39521
chr3 11 28
chr3 16 27
</code></pre></div></div>

<p>Unix’s join is just one of many ways to join data, and is most useful for simple 
quick joins. Joining data by a common column is a common task during data analysis; 
we’ll see how to do this in R later.</p>

<hr />

<h2 id="stream-editing-with-sed">Stream Editing with <code class="highlighter-rouge">sed</code></h2>

<p>Unix pipes are fast because they operate on streams of data (rather than data written to disk). 
Often we need to make trivial edits to a stream, usually to prepare it for the next step in a 
Unix pipeline. The stream editor, or <code class="highlighter-rouge">sed</code>, allows you to do exactly that.</p>

<blockquote class="callout">
  <h2 id="gnu-sed-versus-bsd-sed">GNU Sed versus BSD Sed</h2>
  <p>As with many other Unix tools, the BSD and GNU versions of <code class="highlighter-rouge">sed</code> differ considerably in behavior. 
The GNU version of <code class="highlighter-rouge">sed</code> is usually preferred (and is used here) as it has some additional 
features, and supports functionality such as escape codes for special characters like tab (\t) 
we expect in command-line tools.</p>
</blockquote>

<p><code class="highlighter-rouge">sed</code> reads data from a file or standard input and can edit a line at a time. Let’s look at a very 
simple example: converting a file (chroms.txt) containing a single column of chromosomes in the 
format “chrom12,” “chrom2,” and so on to the format “chr12,” “chr2,” and so on:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">chroms.txt</span><span class="w"> </span><span class="c1"># before sed</span><span class="w">
</span><span class="n">echo</span><span class="w"> </span><span class="s2">"=========="</span><span class="w">
</span><span class="n">sed</span><span class="w"> </span><span class="s1">'s/chrom/chr/'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">chroms.txt</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">3</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>chrom1	3214482	3216968
chrom1	3216025	3216968
chrom1	3216022	3216024
==========
chr1	3214482	3216968
chr1	3216025	3216968
chr1	3216022	3216024
</code></pre></div></div>

<p>It’s a simple but important change: although chroms.txt is a mere 10 lines long, it could 
be 500 gigabytes of data and we can edit it without opening the entire file in memory.</p>

<p>In the preceding code works we uses sed’s substitute command, which has
the syntax <code class="highlighter-rouge">s/pattern/replacement/</code>.</p>

<p>By default, sed only replaces the first occurrence of a match. To 
replace all occurrences of strings that match our pattern we set the global flag g 
after the last slash: <code class="highlighter-rouge">s/pattern/replacement/g</code>. To make matching case-insensitive, 
add the flag i (e.g., <code class="highlighter-rouge">s/pattern/ replacement/i</code>).
By default, sed’s substitutions use POSIX Basic Regular Expressions (BRE). As with 
<code class="highlighter-rouge">grep</code>, we can use the -E option to enable POSIX Extended Regular Expressions (ERE).</p>

<p>We can also capture chunks of text that match a pattern, 
and use these chunks in the replacement (often called grouping and capturing). For 
example the following code captures the chromosome name, and start and end positions 
in a string containing a genomic region in the format “chr1:28427874-28425431”, and 
output this as three columns:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">echo</span><span class="w"> </span><span class="s2">"chr1:28427874-28425431"</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">sed</span><span class="w"> </span><span class="o">-</span><span class="n">E</span><span class="w"> </span><span class="s1">'s/^(chr[^:]+):([0-9]+)-([0-9]+)/\1\t\2\t\3/'</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>chr1	28427874	28425431
</code></pre></div></div>

<p>Note that we capture chunks of text by surrounding matching pattersn with ( and ).</p>

<blockquote class="challenge">
  <h2 id="challenge-5">Challenge 5</h2>

  <p>Come up with some alternative solutions to problem above.
```</p>

  <blockquote class="solution">
    <h2 id="solution-to-challenge-5">Solution to challenge 5</h2>

    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">echo</span><span class="w"> </span><span class="s2">"chr1:28427874-28425431"</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">sed</span><span class="w"> </span><span class="s1">'s/[:-]/\t/g'</span><span class="w">
</span><span class="n">echo</span><span class="w"> </span><span class="s2">"chr1:28427874-28425431"</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">sed</span><span class="w"> </span><span class="s1">'s/:/\t/'</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">sed</span><span class="w"> </span><span class="s1">'s/-/\t/'</span><span class="w"> </span><span class="c1"># or sed -e 's/:/\t/' -e 's/-/\t/</span><span class="w">
</span><span class="n">echo</span><span class="w"> </span><span class="s2">"chr1:28427874-28425431"</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">tr</span><span class="w"> </span><span class="s1">':-'</span><span class="w"> </span><span class="s1">'\t'</span><span class="w">
</span></code></pre></div>    </div>

    <div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>chr1	28427874	28425431
chr1	28427874	28425431
chr1	28427874	28425431
</code></pre></div>    </div>
    <p>Note, that in the last example we use <code class="highlighter-rouge">tr</code> to translate both delimiters to a tab character. 
<code class="highlighter-rouge">tr</code> translates all occurrences of its first argument to its second (see <code class="highlighter-rouge">man tr</code> for more details).</p>

  </blockquote>
</blockquote>

<p>By default, <code class="highlighter-rouge">sed</code> prints every line, making replacements to matching lines. To print only the lines 
that match a pattern, we use the <code class="highlighter-rouge">-n</code> option and than append the <code class="highlighter-rouge">p</code> flag after the last slash:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="o">-</span><span class="n">v</span><span class="w"> </span><span class="s2">"^#"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">sed</span><span class="w"> </span><span class="o">-</span><span class="n">E</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="s1">'s/.*transcript_id "([^"]+)".*/\1/p'</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ENSMUST00000160944
ENSMUST00000160944
</code></pre></div></div>

<p>Note that the example uses an important regular expression idiom: capturing text between delimiters 
(in this case, quotation marks): <code class="highlighter-rouge">"([^"]+)"</code>. In regular extension jargon, the brackets make 
up a character class. Character classes specify what characters the expression is allowed to 
match. Here, we use a caret (^) inside the brackets to match anything except what’s inside these 
brackets.</p>

<p>It’s also possible to select and print certain ranges of lines with sed. In this case, we’re 
not doing pattern matching, so we don’t need slashes:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sed</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="s1">'1,5p'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w">
</span><span class="n">echo</span><span class="w"> </span><span class="s2">"============"</span><span class="w">
</span><span class="n">sed</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="s1">'40,45p'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#!genome-build GRCm38.p2
#!genome-version GRCm38
#!genome-date 2012-01
#!genome-build-accession NCBI:GCA_000001635.4
#!genebuild-last-updated 2013-09
============
1	protein_coding	exon	4352202	4352837	.	-	.	gene_id "ENSMUSG00000025900"; transcript_id "ENSMUST00000027032"; exon_number "2"; gene_name "Rp1"; gene_source "ensembl"; gene_biotype "protein_coding"; transcript_name "Rp1-201"; transcript_source "ensembl"; tag "CCDS"; ccds_id "CCDS14804"; exon_id "ENSMUSE00000232073";
1	protein_coding	CDS	4352202	4352825	.	-	0	gene_id "ENSMUSG00000025900"; transcript_id "ENSMUST00000027032"; exon_number "2"; gene_name "Rp1"; gene_source "ensembl"; gene_biotype "protein_coding"; transcript_name "Rp1-201"; transcript_source "ensembl"; tag "CCDS"; ccds_id "CCDS14804"; protein_id "ENSMUSP00000027032";
1	protein_coding	start_codon	4352823	4352825	.	-	0	gene_id "ENSMUSG00000025900"; transcript_id "ENSMUST00000027032"; exon_number "2"; gene_name "Rp1"; gene_source "ensembl"; gene_biotype "protein_coding"; transcript_name "Rp1-201"; transcript_source "ensembl"; tag "CCDS"; ccds_id "CCDS14804";
1	protein_coding	exon	4351910	4352081	.	-	.	gene_id "ENSMUSG00000025900"; transcript_id "ENSMUST00000027032"; exon_number "3"; gene_name "Rp1"; gene_source "ensembl"; gene_biotype "protein_coding"; transcript_name "Rp1-201"; transcript_source "ensembl"; tag "CCDS"; ccds_id "CCDS14804"; exon_id "ENSMUSE00000154033";
1	protein_coding	CDS	4351910	4352081	.	-	0	gene_id "ENSMUSG00000025900"; transcript_id "ENSMUST00000027032"; exon_number "3"; gene_name "Rp1"; gene_source "ensembl"; gene_biotype "protein_coding"; transcript_name "Rp1-201"; transcript_source "ensembl"; tag "CCDS"; ccds_id "CCDS14804"; protein_id "ENSMUSP00000027032";
1	protein_coding	exon	4343507	4350091	.	-	.	gene_id "ENSMUSG00000025900"; transcript_id "ENSMUST00000027032"; exon_number "4"; gene_name "Rp1"; gene_source "ensembl"; gene_biotype "protein_coding"; transcript_name "Rp1-201"; transcript_source "ensembl"; tag "CCDS"; ccds_id "CCDS14804"; exon_id "ENSMUSE00000232057";
</code></pre></div></div>

<p>Substitutions make up the majority of sed’s usage cases, but <code class="highlighter-rouge">sed</code> has features that allow you 
to make any type of edit to a stream of text. However, for complex stream processing tasks it 
can be easier to write a Python script than a long and complicated sed command. Remember the 
KISS principal: Keep Incredible Sed Simple.</p>

<h2 id="advanced-shell-tricks">Advanced Shell Tricks</h2>

<h3 id="subshells">Subshells</h3>

<p>The first trick we’ll cover is using Unix subshells. Before explaining this trick, it’s helpful 
to remember the difference between sequential commands (connected with &amp;&amp; or ;), and piped commands 
(connected with |). Sequential commands are simply run one after the other. In contrast, connecting two 
programs with pipes means the first program’s standard out will be piped into the next program’s 
standard in.</p>

<p>The difference between sequential commands linked with &amp;&amp; and ; comes down to exit status: if we run 
two commands with <code class="highlighter-rouge">command1 ; command2</code>, command2 will always run, regardless of whether command1 
exits successfully (with a zero exit status). In contrast, if we use <code class="highlighter-rouge">command1 &amp;&amp; command2</code>, command2 
will only run if command1 completed with a zero-exit status. So how do subshells fit into all of this?</p>

<p>Subshells allow us to execute sequential commands together in a separate shell process. This is 
useful primarily to group sequential commands together (such that their output is a single stream). 
This gives us a new way to construct clever oneliners and has practical uses in command-line data 
processing. Let’s look at a toy example first:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">echo</span><span class="w"> </span><span class="s2">"this command"</span><span class="p">;</span><span class="w"> </span><span class="n">echo</span><span class="w"> </span><span class="s2">"that command"</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">sed</span><span class="w"> </span><span class="s1">'s/command/step/'</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>this command
that step
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">echo</span><span class="w"> </span><span class="s2">"this command"</span><span class="p">;</span><span class="w"> </span><span class="n">echo</span><span class="w"> </span><span class="s2">"that command"</span><span class="p">)</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">sed</span><span class="w"> </span><span class="s1">'s/command/step/'</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>this step
that step
</code></pre></div></div>

<p>Grouping both <code class="highlighter-rouge">echo</code> commands together using parentheses causes these two commands to be run 
in a separate subshell, and both commands’ combined standard output is passed to sed. Combining 
two sequential commands’ standard output into a single stream with a subshell is a useful trick, 
and one we can apply to shell problems in bioinformatics.</p>

<p>Consider the problem of sorting a GTF file with a metadata header. We can’t simply sort the entire 
file with sort, because this header could get shuffled in with rows of data. Instead, we want to 
sort everything except the header, but still include the header at the top of the final sorted file. 
We can solve this problem using a subshell to group sequential commands that print the header to 
standard out and sort all other lines by chromosome and start position, printing all lines to standard 
out after the header:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">grep</span><span class="w"> </span><span class="s2">"^#"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="p">;</span><span class="w"> </span><span class="n">grep</span><span class="w"> </span><span class="o">-</span><span class="n">v</span><span class="w"> </span><span class="s2">"^#"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">sort</span><span class="w"> </span><span class="o">-</span><span class="n">k</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="n">k</span><span class="m">4</span><span class="p">,</span><span class="m">4</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">less</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">10</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#!genome-build GRCm38.p2
#!genome-version GRCm38
#!genome-date 2012-01
#!genome-build-accession NCBI:GCA_000001635.4
#!genebuild-last-updated 2013-09
1	pseudogene	gene	3054233	3054733	.	+	.	gene_id "ENSMUSG00000090025"; gene_name "Gm16088"; gene_source "havana"; gene_biotype "pseudogene";
1	unprocessed_pseudogene	exon	3054233	3054733	.	+	.	gene_id "ENSMUSG00000090025"; transcript_id "ENSMUST00000160944"; exon_number "1"; gene_name "Gm16088"; gene_source "havana"; gene_biotype "pseudogene"; transcript_name "Gm16088-001"; transcript_source "havana"; exon_id "ENSMUSE00000848981"; tag "cds_end_NF"; tag "cds_start_NF"; tag "mRNA_end_NF"; tag "mRNA_start_NF";
1	unprocessed_pseudogene	transcript	3054233	3054733	.	+	.	gene_id "ENSMUSG00000090025"; transcript_id "ENSMUST00000160944"; gene_name "Gm16088"; gene_source "havana"; gene_biotype "pseudogene"; transcript_name "Gm16088-001"; transcript_source "havana"; tag "cds_end_NF"; tag "cds_start_NF"; tag "mRNA_end_NF"; tag "mRNA_start_NF";
1	snRNA	exon	3102016	3102125	.	+	.	gene_id "ENSMUSG00000064842"; transcript_id "ENSMUST00000082908"; exon_number "1"; gene_name "Gm26206"; gene_source "ensembl"; gene_biotype "snRNA"; transcript_name "Gm26206-201"; transcript_source "ensembl"; exon_id "ENSMUSE00000522066";
1	snRNA	gene	3102016	3102125	.	+	.	gene_id "ENSMUSG00000064842"; gene_name "Gm26206"; gene_source "ensembl"; gene_biotype "snRNA";
</code></pre></div></div>

<p>We can redirect the output to gzip to compress this stream before writing it to disk:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">zgrep</span><span class="w"> </span><span class="s2">"^#"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf.gz</span><span class="p">;</span><span class="w"> </span><span class="n">zgrep</span><span class="w"> </span><span class="o">-</span><span class="n">v</span><span class="w"> </span><span class="s2">"^#"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf.gz</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">sort</span><span class="w"> </span><span class="o">-</span><span class="n">k</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="n">k</span><span class="m">4</span><span class="p">,</span><span class="m">4</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="err">`</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">gzip</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1_sorted.gtf.gz</span><span class="w">
</span></code></pre></div></div>

<h3 id="named-pipes-and-process-substitution">Named Pipes and Process Substitution</h3>

<p>Throughout this chapter, we’ve used pipes to connect command-line tools to build custom 
data-processing pipelines. However, some programs won’t interface with the Unix pipes 
because they, for example, read in multiple input files and write to multiple output files:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">processing_tool</span><span class="w"> </span><span class="o">--</span><span class="n">in1</span><span class="w"> </span><span class="n">in1.fq</span><span class="w"> </span><span class="o">--</span><span class="n">in2</span><span class="w"> </span><span class="n">in2.fq</span><span class="w"> </span><span class="o">--</span><span class="n">out1</span><span class="w"> </span><span class="n">out2.fq</span><span class="w"> </span><span class="o">--</span><span class="n">out2.fq</span><span class="w">
</span></code></pre></div></div>

<p>Because each file needs to be provided separately, we can’t pipe the previous processing 
step’s results through processing_tool’s standard in. Likewise, this program creates two 
separate output files, so it isn’t possible to pipe it’s standard output to another program 
in the processing pipeline. Fortunately, Unix provides 
a solution: named pipes. A named pipe, also known as a FIFO (First In First Out, a concept in 
computer science), is a special sort of file that is persistent 
on your filesystem. We can create a named pipe with the program mkfifo:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mkfifo</span><span class="w"> </span><span class="n">fqin</span><span class="w">
</span><span class="n">ls</span><span class="w"> </span><span class="o">-</span><span class="n">l</span><span class="w"> </span><span class="n">fqin</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>prw-r--r--  1 dlavrov  staff  0 Mar 13 15:05 fqin
</code></pre></div></div>

<p>You can see that this is indeed a special type of file: the p before the file permissions is 
for pipe. Just like pipes, one process writes data into the pipe, and another process reads 
data out of the pipe. As an example:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">echo</span><span class="w"> </span><span class="s2">"hello, named pipes"</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">fqin</span><span class="w"> </span><span class="o">&amp;</span><span class="w">
</span><span class="n">cat</span><span class="w"> </span><span class="n">fqin</span><span class="w">
</span><span class="n">rm</span><span class="w"> </span><span class="n">fqin</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hello, named pipes
</code></pre></div></div>

<p>Treating the named pipe just as we would any other file, we can access the data we wrote to it 
earlier. Although the syntax is similar to shell redirection to a file, we’re not actually 
writing anything to our disk. Named pipes provide all of the computational benefits of pipes with 
the flexibility of interfacing with files. However, creating and removing them is a bit tedious. 
So there’s a way to use named pipes without having to explicitly create 
them. This is called process substitution, or sometimes known as anonymous named pipes. If we were 
to re-create the previous toy example with process substitution, it would look as follows:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cat</span><span class="w"> </span><span class="o">&lt;</span><span class="p">(</span><span class="n">echo</span><span class="w"> </span><span class="s2">"hello, process substitution"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hello, process substitution
</code></pre></div></div>

<p>The chunk &lt;(echo “hello, process sub stition”) runs the echo command and pipes the output to an 
anonymous named pipe. Your shell then replaces this chunk (the &lt;(…) part) with the path to 
this anonymous named pipe. No named pipes need to be explicitly created, but you get the same 
functionality. Process substitution allows us to connect two (or potentially more) programs, 
even if one doesn’t take input through standard input. This is illustrated in the following figure:</p>

<p><img src="../images/fig7.3.png" alt="" /></p>

<p>In the program example we saw earlier, two inputs were needed (–in1 and –in2). For the sake of 
this example, assume that a program called <code class="highlighter-rouge">makein</code> is creating the input streams for –in1 and –in2. 
We can use process substitution to create two anynyous pipes:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">program</span><span class="w"> </span><span class="o">--</span><span class="n">in1</span><span class="w"> </span><span class="o">&lt;</span><span class="p">(</span><span class="n">makein</span><span class="w"> </span><span class="n">raw1.txt</span><span class="p">)</span><span class="w"> </span><span class="o">--</span><span class="n">in2</span><span class="w"> </span><span class="o">&lt;</span><span class="p">(</span><span class="n">makein</span><span class="w"> </span><span class="n">raw2.txt</span><span class="p">)</span><span class="w"> </span><span class="o">--</span><span class="n">out1</span><span class="w"> </span><span class="n">out1.txt</span><span class="w"> </span><span class="o">--</span><span class="n">out2</span><span class="w"> </span><span class="n">out2.txt</span><span class="w">
</span></code></pre></div></div>

<p>Pprocess substitution can also be used to capture an output stream. For example,</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">program</span><span class="w"> </span><span class="o">--</span><span class="n">in1</span><span class="w"> </span><span class="n">in1.txt</span><span class="w"> </span><span class="o">--</span><span class="n">in2</span><span class="w"> </span><span class="n">in2.txt</span><span class="w"> </span><span class="o">--</span><span class="n">out1</span><span class="w"> </span><span class="o">&gt;</span><span class="p">(</span><span class="n">gzip</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">out1.txt.gz</span><span class="p">)</span><span class="w"> </span><span class="o">--</span><span class="n">out2</span><span class="w"> </span><span class="o">&gt;</span><span class="p">(</span><span class="n">gzip</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">out2.txt.gz</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>will creates two anonymous named pipes, and their input is then passed to the <code class="highlighter-rouge">gzip</code> command. 
<code class="highlighter-rouge">gzip</code> then compresses these and writes to standard out, which we redirect to our gzipped files.</p>

<h2 id="the-unix-philosophy-revisited">The Unix Philosophy Revisited</h2>

<p>Throughout this chapter, we saw how to use a rich set of Unix tools to solve various tasks in
data analysis. Not only are Unix 
piped workflows fast to construct, easy to debug, and versatile, but they’re often the most 
computationally efficient solution, too. It’s a testament to the incredible design of Unix that 
so much of the way we approach modern bioinformatics is driven by the almighty Unix pipe, a 
piece of technology invented over 40 years ago in “one feverish night” by Ken Thompson (as 
described by Doug McIlroy).</p>

<h1 id="extra-topics">EXTRA TOPICS</h1>
<h2 id="1-awk-and-bioawk">1. Awk and Bioawk</h2>
<h3 id="processing-text-with-awk">Processing text with Awk</h3>
<p>We used <code class="highlighter-rouge">awk</code> a few times in the tutorial but here we discussed it in more details.</p>

<p><code class="highlighter-rouge">Awk</code> is a tiny, specialized language that allows you to do a variety of 
text-processing tasks with ease. The key to using Awk effectively is to reserve 
it for the subset of tasks it’s best at — quick data-processing tasks on tabular 
data. Learning Awk will also prepares us to learn <code class="highlighter-rouge">bioawk</code>, which we’ll cover later.</p>

<p>There are two key parts for understanding the Awk language: how Awk processes records, 
and pattern-action pairs. The rest of the language is quite simple.</p>

<ul>
  <li>
    <p>Awk processes input data a record (line) at a time. Each record is composed of fields 
(column entries) that Awk automatically separates. Awk assigns the entire record 
to the variable $0, field one’s value to $1, field two’s value to $2, etc.</p>
  </li>
  <li>
    <p>We build Awk programs using one or more of the following structures: <code class="highlighter-rouge">pattern { action }</code>.
Each pattern is an expression or regular expression pattern. In Awk lingo, these are 
pattern-action pairs and we can chain multiple pattern-action pairs together (separated by semicolons). 
If we omit the pattern, Awk will run the action on all records. If we omit the action but 
specify a pattern, Awk will print all records that match the pattern.</p>
  </li>
</ul>

<p>Let’s see some examples.</p>

<p>First, <code class="highlighter-rouge">awk</code> can mimic <code class="highlighter-rouge">cat</code> by omitting a pattern and printing an entire record with the variable $0:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">awk</span><span class="w"> </span><span class="s1">'{ print $0 }'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example.bed</span><span class="w"> </span><span class="c1">#emulating cat</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>chr1	26	39
chr1	32	47
chr3	11	28
chr1	40	49
chr3	16	27
chr1	9	28
chr2	35	54
chr1	10	19
</code></pre></div></div>

<p>We could even omit the $0, because print called without an argument would print the current record.</p>

<p>Second, <code class="highlighter-rouge">awk</code> can mimic <code class="highlighter-rouge">cut</code> by omitting a patter, but selecting only certain columns:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">awk</span><span class="w"> </span><span class="s1">'{ print $2 "\t" $3 }'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example.bed</span><span class="w"> </span><span class="c1">#emulating cut</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>26	39
32	47
11	28
40	49
16	27
9	28
35	54
10	19
</code></pre></div></div>

<p>Notice that although it was far more typing than using <code class="highlighter-rouge">cut -f2,3</code>, <code class="highlighter-rouge">awk</code> is much more flexible:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">awk</span><span class="w"> </span><span class="s1">'{ print $3 "\t" $2 }'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example.bed</span><span class="w"> </span><span class="c1">#emulating cut</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>39	26
47	32
28	11
49	40
27	16
28	9
54	35
19	10
</code></pre></div></div>

<p>We can incorporate simple pattern matching to select specific records, for example
only lines where the length of the feature (end position - start position) was greater 
than 18:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">awk</span><span class="w"> </span><span class="s1">'$3 - $2 &gt; 18 { print $2 "\t" $3 }'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example.bed</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>9	28
35	54
</code></pre></div></div>

<p>Awk supports arithmetic with the standard operators 
+, -, *, /, % (remainder), and ^ (exponentiation) as well as comparison and logical operations:<br />
a==b  | a!=b | a &lt; b | a &gt; b | a&lt;=b | a&gt;=b | a ~ b | a!~b | a&amp;&amp;b | a||b | !a, were</p>

<p>~ indicates matching regular expression pattern,
&amp;&amp; logical a and b
|| logical a or b
! logical negation</p>

<table>
  <tbody>
    <tr>
      <td>We can also chain patterns, by using logical operators &amp;&amp; (AND),</td>
      <td> </td>
      <td>(OR), and ! (NOT).</td>
    </tr>
  </tbody>
</table>

<p>For example, if we wanted all lines on chromosome 1 with a length greater than 10:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">awk</span><span class="w"> </span><span class="s1">'$1 ~ /chr1/ &amp;&amp; $3 - $2 &gt; 10'</span><span class="w"> </span><span class="n">example.bed</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>awk: can't open file example.bed
 source line number 1
</code></pre></div></div>

<p>The first pattern, $1 ~ /chr1/, is how we specify a regular expression. Regular expressions 
are in slashes.To not match the regular expression we would use !~ (or !($1 ~ /chr1/)).</p>

<p>We can combine patterns and more complex actions than just printing the entire record. For example, 
if we wanted to add a column with the length of this feature (end position - start position) for 
only chromosomes 2 and 3, we could use:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">awk</span><span class="w"> </span><span class="s1">'$1 ~ /chr2|chr3/ { print $0 "\t" $3 - $2 }'</span><span class="w"> </span><span class="n">example.bed</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>awk: can't open file example.bed
 source line number 1
</code></pre></div></div>

<p>Let’s look at some slightly more advanced awk’s feature. <code class="highlighter-rouge">awk</code> recognizes two 
special patterns: BEGIN and END. The BEGIN pattern specifies what to do before 
the first record is read in, and END specifies what to do after the last record’s 
processing is complete. BEGIN is useful to initialize and set up variables, and END 
is useful to print data summaries at the end of file processing.</p>

<p>For example, suppose we wanted to calculate the mean feature length in example.bed. 
We would have to take the sum feature lengths, and then divide by the total number 
of records. We can do this with:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">awk</span><span class="w"> </span><span class="s1">'BEGIN{ s = 0 }; { s += ($3-$2) }; END{ print "mean: " s/NR };'</span><span class="w">
</span></code></pre></div></div>

<p>There’s a special variable we’ve used here, one that Awk automatically assigns in addition 
to $0, $1, $2, etc.: NR. NR is the current record number, so on the last record NR is set 
to the total number of records processed. In this example, we’ve initialized a variable <code class="highlighter-rouge">s</code> 
to 0 in BEGIN (variables you define do not need a dollar sign). Then, for each record we 
increment <code class="highlighter-rouge">s</code> by the length of the feature. At the end of the records, we print this sum <code class="highlighter-rouge">s</code> 
divided by the number of records NR, giving the mean.</p>

<h4 id="setting-field-output-field-and-record-separators">Setting Field, Output Field, and Record Separators</h4>
<p>By default, <code class="highlighter-rouge">awk</code> expects whitespace-separated tabular data, but a 
different field separator can be set with the -F argument. 
It’s also possible to set the record (RS), output field (OFS), and output record (ORS) 
separators. These variables can be set with the -v argument, using the syntax 
<code class="highlighter-rouge">awk -v VAR=val</code>:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">awk</span><span class="w"> </span><span class="o">-</span><span class="nb">F</span><span class="s2">","</span><span class="w"> </span><span class="o">-</span><span class="n">v</span><span class="w"> </span><span class="n">OFS</span><span class="o">=</span><span class="s2">"\t"</span><span class="w"> </span><span class="p">{</span><span class="n">print</span><span class="w"> </span><span class="o">$</span><span class="m">1</span><span class="p">,</span><span class="o">$</span><span class="m">2</span><span class="p">,</span><span class="o">$</span><span class="m">3</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Setting OFS=”\t” saves a few extra characters when outputting tab-delimited results with/ 
statements like print “$1 “\t” $2 “\t” $3.</p>

<p>We saw how to use NR variable to calculate the mean above. We can use it also to extract 
ranges of lines; for example, if we wanted to extract all lines between 3 and 5 (inclusive):</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">awk</span><span class="w"> </span><span class="s1">'NR &gt;= 3 &amp;&amp; NR &lt;= 5'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">example.bed</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>chr3	11	28
chr1	40	49
chr3	16	27
</code></pre></div></div>

<p>Awk makes it easy to convert between bioinformatics files like BED and GTF. For example, 
we could generate a three-column BED file from Mus_musculus.GRCm38.75_chr1.gtf as follows:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">awk</span><span class="w"> </span><span class="s1">'!/^#/ { print $1 "\t" $4-1 "\t" $5 }'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">3</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1	3054232	3054733
1	3054232	3054733
1	3054232	3054733
</code></pre></div></div>

<p>Note that we subtract 1 from the start position to convert to BED format. This is because BED 
uses zero-indexing while GTF uses 1-indexing.</p>

<p>Awk also has a very useful data structure known as an associative array. Associative arrays 
behave like Python’s dictionaries or hashes in other languages. We can create an associative 
array by simply assigning a value to a key. For example, suppose we wanted to count the number 
of features (third column) belonging to the gene “Lypla1.” We could do this by incrementing 
their values in an associative array:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">awk</span><span class="w"> </span><span class="s1">'/Lypla1/ { feature[$3] += 1 }; END { for (k in feature) print k "\t" feature[k] }'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>stop_codon	5
exon	69
UTR	24
CDS	56
start_codon	5
transcript	9
gene	1
</code></pre></div></div>

<p>It’s worth noting that there’s an entirely Unix way to count features of a particular gene: 
grep, cut, sort, and uniq -c:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grep</span><span class="w"> </span><span class="s2">"Lypla1"</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">cut</span><span class="w"> </span><span class="o">-</span><span class="n">f</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">sort</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">uniq</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  56 CDS
  24 UTR
  69 exon
   1 gene
   5 start_codon
   5 stop_codon
   9 transcript
</code></pre></div></div>

<p>However, if we needed to also filter on column-specific information (e.g., strand), an approach 
using just base Unix tools would be quite messy. With Awk, adding an additional filter would be 
trivial: we’d just use &amp;&amp; to add another expression in the pattern.</p>

<h3 id="bioawk-an-awk-for-biological-formats">Bioawk: An Awk for Biological Formats</h3>
<p>Bioawk extends Awk’s powerful processing of tabular data to processing tasks involving common 
bioinformatics formats like FASTA/FASTQ, GTF/GFF, BED, SAM, and VCF. Bioawk is written by Heng Li, 
author of other excellent bioinformatics tools such as BWA and Samtools). You can download, compile, 
and install Bioawk from source, or if you use Mac OS X’s Homebrew package manager, Bioawk is also 
in homebrew-science (so you can install with <code class="highlighter-rouge">brew tap homebrew/science; brew install bioawk</code>).
The basic idea of Bioawk is that we specify what bioinformatics format we’re working with, 
and Bioawk will automatically set variables for each field (just as regular Awk sets the columns 
of a tabular text file to $1, $1, $2, etc.). For Bioawk to set these fields, specify the format 
of the input file or stream with -c. Let’s look at Bioawk’s supported input formats and what 
variables these formats set:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bioawk</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">help</span><span class="w"> </span><span class="n">bed</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bed:
	1:chrom 2:start 3:end 4:name 5:score 6:strand 7:thickstart 8:thickend 9:rgb 10:blockcount 11:blocksizes 12:blockstarts 
sam:
	1:qname 2:flag 3:rname 4:pos 5:mapq 6:cigar 7:rnext 8:pnext 9:tlen 10:seq 11:qual 
vcf:
	1:chrom 2:pos 3:id 4:ref 5:alt 6:qual 7:filter 8:info 
gff:
	1:seqname 2:source 3:feature 4:start 5:end 6:score 7:filter 8:strand 9:group 10:attribute 
fastx:
	1:name 2:seq 3:qual 4:comment 
</code></pre></div></div>

<p>As an example of how this works, let’s read in example.bed and append a column with the length of 
the feature (end position - start position) for all protein coding genes:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bioawk</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">gff</span><span class="w"> </span><span class="s1">'$3 ~ /gene/ &amp;&amp; $2 ~ /protein_coding/ {print $seqname,$end-$start}'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1.gtf</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">4</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1	465597
1	16807
1	5485
1	12533
</code></pre></div></div>

<p>Bioawk is also quite useful for processing FASTA/FASTQ files. For example, we could use it 
to turn a FASTQ file into a FASTA file:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bioawk</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">fastx</span><span class="w"> </span><span class="s1">'{print "&gt;"$name"\n"$seq}'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">contam.fastq</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">4</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bioawk: can't open file ../data/contam.fastq
 source line number 1
</code></pre></div></div>

<p>Note that Bioawk detects whether to parse input as FASTQ or FASTA when we use -c fastx.</p>

<p>Bioawk can also serve as a method of counting the number of FASTQ/FASTA entries:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bioawk</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">fastx</span><span class="w"> </span><span class="s1">'END{print NR}'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">contam.fastq</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bioawk: can't open file ../data/contam.fastq
 source line number 1
</code></pre></div></div>

<p>Or Bioawk’s function <code class="highlighter-rouge">revcomp()</code> can be used to reverse complement a sequence:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bioawk</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">fastx</span><span class="w"> </span><span class="s1">'{print "&gt;"$name"\n"revcomp($seq)}'</span><span class="w"> </span><span class="n">contam.fastq</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">4</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bioawk: can't open file contam.fastq
 source line number 1
</code></pre></div></div>

<p>Bioawk is also useful for creating a table of sequence lengths from a FASTA file. 
For example, to create a table of all chromosome lengths of the Mus musculus genome:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bioawk</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">fastx</span><span class="w"> </span><span class="s1">'{print $name,length($seq)}'</span><span class="w"> </span><span class="n">Mus_musculus.GRCm38.75.dna_rm.toplevel.fa.gz</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">mm_genome.txt</span><span class="w">
</span><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="n">mm_genome.txt</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bioawk: can't open file Mus_musculus.GRCm38.75.dna_rm.toplevel.fa.gz
 source line number 1
</code></pre></div></div>

<p>Finally, Bioawk has two options that make working with plain tab-delimited files easier: 
-t and -c hdr. -t is for processing general tab-delimited files; it sets Awk’s field 
separator (FS) and output field separator (OFS) to tabs. The option -c hdr is for 
unspecific tab-delimited formats with a header as the first line. This option sets 
field variables, but uses the names given in the header. Suppose we had a simple 
tab-delimited file containing variant names and genotypes for individuals (in columns):</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">head</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">genotypes.txt</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>head: ../data/genotypes.txt: No such file or directory
</code></pre></div></div>

<p>If we wanted to return all variants for which individuals ind_A and ind_B have identical genotypes
(note that this assumes a fixed allele order like ref/alt or major/minor):</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bioawk</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">hdr</span><span class="w"> </span><span class="s1">'$ind_A == $ind_B {print $id}'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">genotypes.txt</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bioawk: can't open file ../data/genotypes.txt
 source line number 1
</code></pre></div></div>

<h2 id="2-decoding-plain-text-data-hexdump">2. Decoding Plain-Text Data: hexdump</h2>
<p>In bioinformatics, the plain-text data we work with is often encoded in ASCII. ASCII is a character encoding 
scheme that uses 7 bits to represent 128 different values, including letters (upper- and lowercase),
numbers, and special nonvisible characters. While ASCII only uses 7 bits, nowadays computers use an 8-bit byte 
to store ASCII characters. More information about ASCII is available in your terminal through man ascii. Because 
plain-text data uses characters to encode information, our encoding scheme matters. When working with a plain-text 
file, 98% of the time you won’t have to worry about the details of ASCII and how your file is encoded. However, 
the 2% of the time when encoding does matter—usually when an invisible non-ASCII character has entered data—
it can lead to major headaches. In this section, we’ll cover the basics of inspecting text data at a low level 
to solve these types of problems. If you’d like to skip this section for now, bookmark it in case you run into 
this issue at some point.</p>

<p>First, to look at a file’s encoding use the program <code class="highlighter-rouge">file</code>, which infers what the encoding is from the file’s 
content. For example, we see that many of the example files we’ve been working with in this chapter are ASCII-encoded:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">file</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">Mus_musculus.GRCm38.75_chr1</span><span class="o">*</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>../data/Mus_musculus.GRCm38.75_chr1.bed:       ASCII text
../data/Mus_musculus.GRCm38.75_chr1.gtf:       ASCII text, with very long lines
../data/Mus_musculus.GRCm38.75_chr1_bed.csv:   ASCII text
../data/Mus_musculus.GRCm38.75_chr1_genes.txt: ASCII text
</code></pre></div></div>

<p>Some files will have non-ASCII encoding schemes, and may contain special characters. The most common character 
encoding scheme is UTF-8, which is a superset of ASCII but allows for special characters. For example, the utf8.txt 
included in the GitHub directory is a UTF-8 file, as evident from file’s output:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">file</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">utf8.txt</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>../data/utf8.txt: UTF-8 Unicode English text
</code></pre></div></div>

<p>Because UTF-8 is a superset of ASCII, if we were to delete the special characters in this file and save it, 
file would return that this file is ASCII-encoded. Most files you’ll download from data sources like Ensembl, 
NCBI, and UCSC’s Genome Browser will not have special characters and will be ASCII-encoded. Often, the problems 
you’ll run into are from data generated by humans, which through copying and pasting data from other sources may 
lead to unintentional special characters. For example, the improper.fa file in the GitHub repository looks like 
a regular FASTA file upon first inspection:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cat</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">improper.fa</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;good-sequence
AGCTAGCTACTAGCAGCTACTACGAGCATCTACGGCGCGATCTACG
&gt;bad-sequence
GATCAGGCGACATCGAGCTATCACTACGAGCGAGΑGATCAGCTATT
</code></pre></div></div>

<p>However, finding the reverse complement of these sequences using `bioawk (don’t worry about the details of this 
program yet—we’ll cover it later) leads to strange results:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bioawk</span><span class="w"> </span><span class="o">-</span><span class="n">cfastx</span><span class="w"> </span><span class="s1">'{print revcomp($seq)}'</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">improper.fa</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CGTAGATCGCGCCGTAGATGCTCGTAGTAGCTGCTAGTAGCTAGCT
AATAGCTGATC
</code></pre></div></div>

<p>What’s going on? We have a non-ASCII character in our second sequence:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">file</span><span class="w"> </span><span class="n">..</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">improper.fa</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>../data/improper.fa: UTF-8 Unicode text
</code></pre></div></div>

<p>We can use <code class="highlighter-rouge">hexdump</code> program to identify which letter is causing this problem. 
The hexdump program returns the hexadecimal values of each character. 
With the -c option, this also prints the character:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hexdump</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">data</span><span class="o">/</span><span class="n">improper.fa</span><span class="w">
</span></code></pre></div></div>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hexdump: data/improper.fa: No such file or directory
hexdump: data/improper.fa: Bad file descriptor
</code></pre></div></div>

<p>As we can see, the character after “CGAGCGAG” in the second sequence is clearly not an ASCII character. 
Another way to see non-ASCII characters is using grep with an option to look for 
characters outside a hexadecimal range: <code class="highlighter-rouge">grep --color='auto' -P '[\x80-\xFF] improper.fa</code>. Note that this 
does not work with BSD grep, the version that comes with Mac OS X.</p>


<blockquote class="keypoints">
  <h2>Key Points</h2>
  <ul>
    
    <li><p>Use <code class="highlighter-rouge">wget</code> and <code class="highlighter-rouge">curl</code> to download data</p>
</li>
    
    <li><p>Use <code class="highlighter-rouge">head</code> and <code class="highlighter-rouge">tail</code> to inspect data</p>
</li>
    
    <li><p>Use <code class="highlighter-rouge">less</code> to view data and to build pipelines</p>
</li>
    
    <li><p>Use <code class="highlighter-rouge">wc</code>, <code class="highlighter-rouge">ls</code>, and <code class="highlighter-rouge">awk</code> to obtain data summary</p>
</li>
    
    <li><p>Use <code class="highlighter-rouge">cut</code> to select specific columns</p>
</li>
    
    <li><p>Use <code class="highlighter-rouge">grep</code> to search for patterns</p>
</li>
    
    <li><p>Use <code class="highlighter-rouge">sort</code> to sort data and <code class="highlighter-rouge">unique</code> to find unique records</p>
</li>
    
    <li><p>Use <code class="highlighter-rouge">sed</code> to edit data streams</p>
</li>
    
    <li><p>Use <code class="highlighter-rouge">$()</code> to include an output from a program in a string</p>
</li>
    
  </ul>
</blockquote>

</article>

<div class="row">
  <div class="col-xs-1">
    <h3 class="text-left">
      
      <a href="../01-unix-git-intro/index.html"><span class="glyphicon glyphicon-menu-left" aria-hidden="true"></span><span class="sr-only">previous episode</span></a>
      
    </h3>
  </div>
  <div class="col-xs-10">
    
  </div>
  <div class="col-xs-1">
    <h3 class="text-right">
      
      <a href="../03-bash-scripts/index.html"><span class="glyphicon glyphicon-menu-right" aria-hidden="true"></span><span class="sr-only">next episode</span></a>
      
    </h3>
  </div>
</div>


      
      
<footer>
  <div class="row">
    <div class="col-md-6" align="left">
      <h4>
	Copyright &copy; 2016–2018
	
	<a href="https://software-carpentry.org">Software Carpentry Foundation</a>
	
      </h4>
    </div>
    <div class="col-md-6" align="right">
      <h4>
	
	<a href="/edit/gh-pages/_episodes/02-unix-data-tools.md">Edit on GitHub</a>
	
	/
	<a href="/blob/gh-pages/CONTRIBUTING.md">Contributing</a>
	/
	<a href="/">Source</a>
	/
	<a href="/blob/gh-pages/CITATION">Cite</a>
	/
	<a href="mailto:dlavrov@iastate.edu">Contact</a>
      </h4>
    </div>
  </div>
</footer>

      
    </div>
    
<script src="../assets/js/jquery.min.js"></script>
<script src="../assets/js/bootstrap.min.js"></script>
<script src="../assets/js/lesson.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-37305346-2', 'auto');
  ga('send', 'pageview');
</script>

  </body>
</html>
